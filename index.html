<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <meta name="description" content="ACII25 Tutorial - Understanding and Mitigating Bias in Emotion Recognition Systems">
    <meta name="author" content="Woan-Shiuan Chien">
    <link rel="image_src" href="img/CVPR2023.png" />

    <!-- Meta properties -->
    <meta property="og:title" content="ACII25 Tutorial - Understanding and Mitigating Bias in Emotion Recognition Systems">
    <meta property="og:description" content="Presentation of the ACII25 tutorial">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://woanshiuanchien.github.io/bias-in-emotion-recognition-system//">
    <meta property="og:image" content="img/CVPR2023.png"/>

    <title>ACII25 Tutorial - Understanding and Mitigating Bias in Emotion Recognition Systems</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Josefin+Slab:100,300,400,600,700,100italic,300italic,400italic,600italic,700italic" rel="stylesheet" type="text/css">

    <!-- Custom styles for this template -->
    <link href="main.css" rel="stylesheet">

    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  </head>

  <body>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" />

    
    <section id="title">
    <div class="container py-7 bg-orange">
        <h1 class="text-letter-spacing-xs my-0 text-primary font-weight-bold text-center">
            
            Understanding and Mitigating Bias in Emotion Recognition Systems
        </h1>
        <br>
        <h2 class="text-sm text-dark text-center">
          ACII 2025 Tutorial
        </h2>
        <p class="text-sm text-dark text-center">
          Saturday, October 11st 2025 - Canberra<br>
          <a href="#"><i class="fa fa-youtube-play" style="font-size:48px;color:red"></i></a>
        </p>
    </div>
    </section>

    <section id="bod">
    <div class="container bg-orange" >								
        <h2 class="text-uppercase text-letter-spacing-xs my-0 text-primary font-weight-bold text-center">
            Organizers
        </h2>
        <br>
        <div class="row text-center">
            <div class="col-lg-6 col-sm-6 col-xs-12 wow fadeInLeft" data-wow-duration="1s" data-wow-delay="0.1s" data-wow-offset="0" style="visibility: visible; animation-duration: 1s; animation-delay: 0.1s; animation-name: fadeInLeft;">
                <div class="our-bod">
                    <div class="single-bod">
                        <a href="https://woanshiuanchien.github.io">
                            <img src="img/winnie.jpg" class="img-fluid cimg" alt="">
                            <h3 class="text-bold text-name">Woan-Shiuan Chien</h3>
                        </a>
                        <p class="text-institute">National Tsing Hua University</p>
                    </div>
                </div>
            </div><!--- END COL -->	
            <div class="col-lg-6 col-sm-6 col-xs-12 wow fadeInLeft" data-wow-duration="1s" data-wow-delay="0.2s" data-wow-offset="0" style="visibility: visible; animation-duration: 1s; animation-delay: 0.2s; animation-name: fadeInLeft;">
                <div class="our-bod">
                    <div class="single-bod">
                        <a href="https://biic.ee.nthu.edu.tw/biicers.php">
                            <img src="img/jeremy.png" class="img-fluid" alt="">
                            <h3 class="text-bold text-name">Chi-Chun Lee</h3>
                        </a>
                        <p class="text-institute">National Tsing Hua University</p>
                    </div>						
                </div>
            </div><!--- END COL --> 
        </div><!--- END ROW -->			
    </div><!--- END CONTAINER -->
    </section>

    <div class="container py-7 bg-orange">
      <h2 class="text-uppercase text-letter-spacing-xs my-0 text-primary font-weight-bold text-center">
          Summary
      </h2>
      <br>
      <p class="text-sm text-dark centered-aligned">
        Human perception and expression of emotion are profoundly shaped by individual traits, social norms, and cultural values. Emotion recognition systems, which aim to infer emotional states from speech, facial ex-pression, or physiological signals, inevitably reflect biases embedded in their training data, annotation processes, and model assumptions. These biases can stem from subjective labeling practices, un-balanced demographic representation, or cultural misalignments. As a result, such systems may systemat-ically underperform or behave inconsistently across gender, age, accent, or ethnic groups. This raises ethical concerns in applications where emotional AI interacts with diverse users, including mental health moni-toring, education, and public services. A reliable emotion recognition system must not only be accurate but also inclusive, ensuring that users feel seen, heard, and respected.
      </p>
      <p class="text-sm text-dark centered-aligned">
        In recent years, bias in machine learning and AI systems has gained increasing attention, particularly due to its impact on equity, accountability, and societal trust. This growing awareness has led to broader discussions on fairness as a normative goal, with major conferences such as NeurIPS, FAccT, and ICML hosting tutorials and special sessions on responsible AI, debiasing strategies, and trustworthy system design. While these efforts have advanced our understanding of bias in algorithmic decision-making, they often focus on general prediction tasks and lack a pipeline-specific perspective for emotion. Affective computing poses unique challenges due to its reliance on interpreting inherently ambiguous and subjective human emotions. In these systems, bias may emerge during model training and in upstream stages like annotation, where human raters’ perspectives and demographic backgrounds play a significant role. Achieving fairness in emotion recognition therefore requires more than accuracy; it must also consider how individuals feel perceived, valued, and represented by the system. In this context, both the annotation process and the model prediction carry potential for human-centered bias.
		</p>
  </div>

    <div class="container py-7 bg-orange">
        <h2 class="text-uppercase text-letter-spacing-xs my-0 text-primary font-weight-bold text-center">
          Details & Schedule
        </h2>
        <br>
        <div class="sched-div mb-2 center" id="Friday, Nov 13th">
          <h4 class="mt-0 mb-2 text-dark op-8 font-weight-bold">
            Saturday, October 11st
          </h4>
          <p class="text-sm text-dark">
            Time zone:	<a href="https://www.timeanddate.com/time/zone/australia/canberra">AEST — Australian Eastern Standard Time</a> <br>
            Location: Hotel Realm conference venue, <b> </b> <br>
            More details: <a href="#https://acii-conf.net/2025/tutorials/"> ACII tutorial page</a><br>
            <font color="#303030"><b>NEWS:</b> recording available <a href="#">here</a>.</font>
          </p>
          <ul class="list-timeline list-timeline-primary">
<li class="list-timeline-item p-0 pb-3 pb-lg-4 d-flex flex-wrap flex-column">
  <p class="my-0 text-dark flex-fw text-sm">
    <span class="text-inverse op-8">09:15 - 09:30</span> - <i>Setting the Stage: Why Bias Matters in Emotion AI</i><br>
    A human-centered overview of how bias emerges in affective computing and why it poses challenges for socially responsible emotion recognition.
  </p>
</li>

<li class="list-timeline-item p-0 pb-3 pb-lg-4 d-flex flex-wrap flex-column">
  <p class="my-0 text-dark flex-fw text-sm">
    <span class="text-inverse op-8">09:30 - 10:10</span> - <i>Sources of Bias & Case Study: Speech Emotion Recognition</i><br>
    Where does bias come from? Annotation subjectivity, demographic gaps.<br>
    Why is SER particularly sensitive to bias? Speaker- and rater-side analysis, dataset evidence.
  </p>
</li>

<li class="list-timeline-item p-0 pb-3 pb-lg-4 d-flex flex-wrap flex-column">
  <p class="my-0 text-dark flex-fw text-sm">
    <span class="text-inverse op-8">10:10 - 10:25</span> - Break
  </p>
</li>

<li class="list-timeline-item p-0 pb-3 pb-lg-4 d-flex flex-wrap flex-column">
  <p class="my-0 text-dark flex-fw text-sm">
    <span class="text-inverse op-8">10:25 - 11:00</span> - <i>Mitigating Bias Across the Pipeline: Data, Models, and Metrics</i><br>
    Bias-aware Data Practices: Inclusive annotation, dataset auditing, labeling diversity.<br>
    Model-side Mitigation Strategies: Pre-, in-, and post-processing strategies.<br>
    Evaluation Methods: Group-level and individual-level assessment to quantify residual bias and guide fairness goals.
  </p>
</li>

<li class="list-timeline-item p-0 pb-3 pb-lg-4 d-flex flex-wrap flex-column">
  <p class="my-0 text-dark flex-fw text-sm">
    <span class="text-inverse op-8">11:00 - 11:10</span> - <i>Societal Implications and Open Problems</i><br>
    Implications of unresolved bias in emotion AI across cultures and contexts. The importance of perception, user trust, and equitable system behavior.
  </p>
</li>

<li class="list-timeline-item p-0 pb-3 pb-lg-4 d-flex flex-wrap flex-column">
  <p class="my-0 text-dark flex-fw text-sm">
    <span class="text-inverse op-8">11:10 - 11:40</span> - <i>Interactive Hands-on Session: Fairness Analysis in BIIC-Podcast</i><br>
    Practical walkthrough using bias mitigation techniques, with fairness metrics applied to a real-world speech emotion dataset.
  </p>
</li>

          </ul>
        </div>
    </div>

    <div class="container py-7 bg-orange">
        <p class="text-sm text-dark text-center">For details, please contact <a href="mailto:wschien@gapp.nthu.edu.tw" style="font-weight: normal;">Woan-Shiuan Chien</a>.
            <br>
            Last updated: 27th or September 2025.<br>
			Website credit: This website style is adopted from the <a href="https://osimeoni.github.io/object-localization-for-free/">CVPR23 tutorial page</a>.
        </p>
    </div>

  </body>

</html>
